exec_env := "das5"

export BENCHMARK_JAR := "../target/scala-2.13/provxlib-assembly-0.1.0-SNAPSHOT.jar"
export EXPERIMENTS_DIR := if exec_env == "local" {
  "/Users/gm/vu/thesis/impl/provxlib/run/experiments"
} else if exec_env == "das5" {
  "/var/scratch/gmo520/thesis/experiments"
} else {
  error("unknown environment")
}

export DOWNLOAD_DIR := if exec_env == "local" {
  "/Users/gm/vu/thesis/data/raw"
} else if exec_env == "das5" {
  "/var/scratch/gmo520/thesis/data/raw"
} else {
  error("unknown environment")
}

export LOCAL_DATASET_DIR := if exec_env == "local" {
  "/Users/gm/vu/thesis/data/graphs"
} else if exec_env == "das5" {
  "/var/scratch/gmo520/thesis/data/graphs"
} else {
  error("unknown environment")
}

export RUNNER_CONFIG := if exec_env == "local" {
  "./config.local.properties"
} else if exec_env == "das5" {
  "/home/gmo520/provxlib/run/config.das5.properties"
} else {
  error("unknown environment")
}


# Environment variables required for Spark setup
@env:
	touch env
	echo 'export JAVA_HOME="/usr/lib/jvm/jre-11/"' > env
	cat /home/gmo520/spark-exec/provx-$(squeue -u gmo520 | tail -n 1 | awk '{ print $1 }').out | grep -P 'export (SPARK_|HADOOP_)' | sed 's/^\*\s*//g' >> env
	echo 'export PATH="$HADOOP_HOME/bin:$PATH"' >> env
	echo 'export PATH="$SPARK_HOME/bin:$PATH"' >> env

# Copy graph datasets to HDFS
copy: env
	#!/usr/bin/env bash
	source ./env
	hadoop fs -copyFromLocal $LOCAL_DATASET_DIR /graphs

# DESTRUCTIVE: delete experiments directory
clean-local: env
  #!/usr/bin/env bash
  source ./env
  # TODO: ask for user to confirm before proceeding
  rm -r $EXPERIMENTS_DIR
  mkdir -p $EXPERIMENTS_DIR

# Clean HDFS directories
clean-hdfs: env
	#!/usr/bin/env bash
	source ./env
	dirs=(
	  /lineage
	  /results
	  /output
	  /spark-logs
	)
	for dir in ${dirs[@]}; do
	  hadoop fs -rm -r -f $dir
	  hadoop fs -mkdir -p $dir
	done

clean: clean-hdfs #clean-local

# Clean directories and copy graphs to HDFS
setup: download decompress clean copy

# Run benchmark
bench description: env
  #!/usr/bin/env bash
  source ./env
  spark-submit --class lu.magalhaes.gilles.provxlib.benchmark.Runner provxlib-assembly-0.1.0-SNAPSHOT.jar --config $RUNNER_CONFIG --description "{{ description }}" > >(tee runner.stdout.log) 2> >(tee runner.stderr.log >&2)
  # post
  #ARCHIVE_FOLDER=$(cat runner.stdout.log | grep 'Experiments path' | tail -n 1 | cut -d ':' -f 2 | sed 's/ //')
  #cp runner.stdout.log runner.stderr.log $ARCHIVE_FOLDER


# Decompress compressed graph datasets
decompress:
	#!/bin/bash

	mkdir -p $LOCAL_DATASET_DIR
	
	for file in $DOWNLOAD_DIR/*.tar.zst; do
		if [ ! -f $LOCAL_DATASET_DIR/$(basename $file .tar.zst).v ]; then
			echo "Decompressing $file"
			tar -C $LOCAL_DATASET_DIR --use-compress-program=unzstd -xvf $file &
		fi
	done
	wait 

# Download graph datasets from LDBC Graphalytics
download:
	#!/bin/bash
	
	base_url="https://pub-383410a98aef4cb686f0c7601eddd25f.r2.dev/graphalytics/"

	datasets=(
		# XS datasets
		"kgs.tar.zst"
		"wiki-Talk.tar.zst"
		"cit-Patents.tar.zst"
	
		# S datasets
		# "datagen-7_5-fb.tar.zst"
		# "datagen-7_6-fb.tar.zst"
		# "datagen-7_7-zf.tar.zst"
		# "datagen-7_8-zf.tar.zst"
		# "datagen-7_9-fb.tar.zst"
		# "dota-league.tar.zst"
		# "graph500-22.tar.zst"
	)
	for dataset in ${datasets[@]}; do
		dataset_path=$DOWNLOAD_DIR/$dataset
		if [ ! -f $dataset_path ]; then
			url=$base_url$dataset
			echo "Downloading $url"
			wget -P $DOWNLOAD_DIR $url &
		fi
	done
	
	wait 

